---
layout: post
title: Exercises (Part 1)
mathjax: true
---

Má»¥c lá»¥c:

- [BÃ i 1.1](#bÃ i-11)
- [BÃ i 1.2](#bÃ i-12)
- [BÃ i 1.3](#bÃ i-13)

## BÃ i 1.1

PhÆ°Æ¡ng trÃ¬nh (1.1) nhÆ° sau:

$$
y(x, \mathbf{w}) = \sum_{j=0}^M x^j w_{j}
$$

PhÆ°Æ¡ng trÃ¬nh (1.2) nhÆ° sau:

$$
E(\mathbf{w}) = \frac{1}{2} \sum_{n=1}^N \left\{ y(x_{n}, \mathbf{w}) - t_{n} \right\}^2
$$

vá»›i $(x_1, \dots, x_{n})$ lÃ  cÃ¡c dá»¯ liá»‡u, $(t_{1}, \dots, t_{n})$ lÃ  cÃ¡c nhÃ£n (hay lÃ  target) vÃ  $\mathbf{w}$ lÃ  bá»™ tham sá»‘. Äá»ƒ cá»±c tiá»ƒu Ä‘Æ°á»£c hÃ m lá»—i $E(\mathbf{w})$, ta chá»‰ cáº§n tÃ¬m giÃ¡ trá»‹ $\hat{\mathbf{w}}$, sao cho:

$$
\nabla E(\hat{\mathbf{w}}) = \mathbf{0}
$$

vá»›i $\mathbf{0}$ lÃ  vector $0$. Do $\nabla E(\mathbf{w})$ lÃ  má»™t vector nÃªn Ä‘á»ƒ vector báº±ng $0$ thÃ¬ tá»«ng pháº§n tá»­ báº±ng $0$, váº­y ta cáº§n tÃ¬m $\hat{w}_{i}$ sao cho:

$$
\frac{\partial{E(\hat{\mathbf{w}})}}{\partial w_{i}} = 0
$$

Giá» báº¯t Ä‘áº§u biáº¿n Ä‘á»•i Ä‘á»ƒ tÃ¬m Ä‘Æ°á»£c $\hat{w}_i$ thÃ´i nÃ o. Ta cÃ³:

$$
\begin{aligned}
\frac{\partial{E(\hat{\mathbf{w}})}}{\partial w_{i}} &= \frac{1}{2} \sum_{n=1}^N \frac{\partial \{y(x_{n}, \mathbf{w}) - t_{n}\}^2}{\partial w_{i}} \\
&= \frac{1}{2} \sum_{n=1}^N \left[ \frac{\partial y(x_{n}, \mathbf{w})^2}{\partial w_{i}} - 2t_{n} \frac{\partial y(x_{n}, \mathbf{w})}{\partial w_{i}} + \frac{\partial t_{n}^2}{\partial w_{i}} \right] \\
&= \frac{1}{2} \sum_{n=1}^N \left[ 2y(x_{n}, \mathbf{w})\frac{\partial y(x_{n}, \mathbf{w})}{\partial w_{i}} - 2t_{n}x_{n}^i +0 \right] \\
&= \frac{1}{2} \sum_{n=1}^N [2y(x_{n}, \mathbf{w})x_{n}^i -2t_{n}x_{n}^i] \\
&= \sum_{n=1}^N \left[ \sum_{j=0}^M x_{n}^{i+j} w_{j} \right] - \sum_{n=1}^Nt_{n}x_{n}^i
\end{aligned}
$$

á» phÆ°Æ¡ng trÃ¬nh trÃªn, tÃ¡ch pháº§n trÆ°á»›c dáº¥u trá»«, ta Ä‘Æ°á»£c:

$$
\begin{aligned}
\sum_{n=1}^N \left[ \sum_{j=0}^M x_{n}^{i+j} w_{j} \right] &= \sum_{n=1}^N (x_{n}^{i}w_{0} + \dots x_{n}^{i+M}w_{M}) \\
&= \sum_{n=1}^N x_{n}^iw_{0} + \dots + \sum_{n=1}^N x_{n}^{i+M}w_{M} \\
&= \sum_{j=0}^M \left( \sum_{n=1}^N x_{n}^{i+j} \right) w_{j}
\end{aligned}
$$

Thay vÃ o láº¡i phÆ°Æ¡ng trÃ¬nh chá»— ta cÃ³:

$$
\begin{aligned}
\frac{\partial{E(\hat{\mathbf{w}})}}{\partial w_{i}} &= \sum_{n=1}^N \left[ \sum_{j=0}^M x_{n}^{i+j} w_{j} \right] - \sum_{n=1}^Nt_{n}x_{n}^i \\
&= \sum_{j=0}^M \left( \sum_{n=1}^N x_{n}^{i+j} \right) w_{j} - \sum_{n=1}^N t_{n}x_{n}^i
\end{aligned}
$$

Äáº·t $\sum_{n=1}^N x_{n}^{i+j} = A_{ij}$ vÃ  $\sum_{n=1}^Nt_{n}x_{n}^i = T_{i}$. Khi Ä‘Ã³:

$$
\begin{aligned}
\frac{\partial E(\mathbf{w})}{\partial w_{i}} &= 0 \\
\Leftrightarrow \sum_{j=0}^M A_{ij}w_{j} &= T_{i}
\end{aligned}
$$

Váº­y giÃ¡ trá»‹ $\hat{w}_i$ cáº§n tÃ¬m chÃ­nh lÃ  nghiá»‡m cá»§a phÆ°Æ¡ng trÃ¬nh trÃªn.

## BÃ i 1.2

PhÆ°Æ¡ng trÃ¬nh (1.122) lÃ  phÆ°Æ¡ng trÃ¬nh nghiá»‡m $\hat{w}_i$ á»Ÿ bÃ i 1.1. CÃ²n phÆ°Æ¡ng trÃ¬nh (1.4) nhÆ° sau:

$$
\tilde{E}(\mathbf{w}) = \frac{1}{2} \sum_{n=1}^N \{y(x_{n}, \mathbf{w}) - t_{n}\}^2 + \frac{\lambda}{2}||\mathbf{w||^2}
$$

trong Ä‘Ã³ $\|\mathbf{w}\|$ Ä‘Æ°á»£c gá»i lÃ  **chuáº©n** cá»§a vector $\mathbf{w}$ vÃ  cÃ³ cÃ´ng thá»©c lÃ :

$$
\|\mathbf{w}\| = \sqrt{ w_{0}^2 + \dots + w_{M}^2 }
$$

Ta cÃ³:

$$
\begin{aligned}
\frac{\partial{E(\hat{\mathbf{w}})}}{\partial w_{i}} &= \frac{1}{2} \sum_{n=1}^N \frac{\partial \left( \{y(x_{n}, \mathbf{w}) - t_{n}\}^2 +\frac{\lambda}{2}||\mathbf{w}||^2 \right)}{\partial w_{i}} \\
&= \frac{1}{2} \sum_{n=1}^N \left[ \frac{\partial y(x_{n}, \mathbf{w})^2}{\partial w_{i}} - 2t_{n} \frac{\partial y(x_{n}, \mathbf{w})}{\partial w_{i}} + \frac{\partial t_{n}^2}{\partial w_{i}} + \frac{\lambda}{2} \frac{\partial||\mathbf{w}||^2}{\partial w_{i}} \right] \\
&= \sum_{j=0}^M A_{ij}w_{j} -T_{i} + \sum_{n=1}^N \lambda w_{i} \\
&= \sum_{j=0}^M A_{ij}w_{j} -T_{i} + N\lambda w_{i} \\
\end{aligned}
$$

Váº­y giÃ¡ trá»‹ $\hat{w}_i$ chÃ­nh lÃ  nghiá»‡m cá»§a phÆ°Æ¡ng trÃ¬nh:

$$
\sum_{j=0}^M A_{ij}w_{j} + N\lambda w_{i} = T_{i}
$$

## BÃ i 1.3

BÃ i nÃ y giáº£i khÃ¡ tÆ°Æ¡ng tá»± bÃ i trong pháº§n [[Introduction (Prob)]]. MÃ¬nh Ä‘áº·t biáº¿n ngáº«u nhiÃªn $B$ Ä‘áº¡i diá»‡n cho cÃ¡c há»™p mÃ u, biáº¿n ngáº«u nhiÃªn $F$ Ä‘áº¡i diá»‡n cho trÃ¡i cÃ¢y, $F= a$ lÃ  trÃ¡i tÃ¡o (apple), $F = o$ lÃ  trÃ¡i cam (orange) vÃ  $F = l$ lÃ  trÃ¡i chanh (lime). Ta cÃ³:

$$
\begin{aligned}
p(B = r) &= 0.2 \\
p(B = b) &= 0.2 \\
p(B = g) &= 0.6
\end{aligned}
$$

Tiáº¿p theo, ta cÃ³ xÃ¡c suáº¥t chá»n Ä‘Æ°á»£c trÃ¡i tÃ¡o khi Ä‘Ã£ chá»n Ä‘Æ°á»£c má»™t há»™p mÃ u láº§n lÆ°á»£t lÃ :

$$
\begin{aligned}
p(F = a \mid B = r) &= \frac{3}{10} = 0.3 \\
p(F = a \mid B = b) &= \frac{1}{2} = 0.5 \\
p(F = a \mid B = g) &= \frac{3}{10} = 0.3
\end{aligned}
$$

DÃ¹ng sum rule, ta láº¡i cÃ³:

$$
\begin{aligned}
p(F = a) &= \sum_{B} p(F=a, B) \\
&= \sum_{B} p(F=a \mid B)p(B) \\
&= p(F=a \mid B = r)p(B = r) + p(F=a \mid B=b)p(B=b) \\
&+ p(F=a \mid B=g)p(B = g) \\
&= 0.3 \times 0.2 + 0.5 \times 0.2 + 0.3 \times 0.6 \\
&= 0.34
\end{aligned}
$$

Váº­y xÃ¡c suáº¥t Ä‘á»ƒ chá»n Ä‘Æ°á»£c má»™t quáº£ tÃ¡o lÃ  $0.34$. Äá»ƒ tÃ¬m xÃ¡c suáº¥t há»™p ta chá»n lÃ  há»™p xanh lÃ¡ $g$ khi Ä‘Ã£ chá»n Ä‘Æ°á»£c quáº£ tÃ¡o, ta tÃ¬m xÃ¡c suáº¥t $p(B = g \mid F = a)$ báº±ng cÃ¡ch dÃ¹ng Ä‘á»‹nh lÃ½ Bayes:

$$
p(B = g \mid F= a) = \frac{p(F=a \mid B=g)p(B =g)}{p(F=a)} = \frac{0.3 \times 0.6}{0.34} \approx 0.52
$$

## BÃ i 1.4

**WARNING: BÃ i nÃ y khÃ¡ hardcore ğŸ’€**

Giáº£ sá»­ ta cÃ³ hÃ m kháº£ vi $f(x)$ vá»›i $x$ lÃ  sá»‘ thá»±c (khÃ´ng pháº£i biáº¿n ngáº«u nhiÃªn), Ä‘á»ƒ tÃ¬m giÃ¡ trá»‹ lá»›n nháº¥t cá»§a $f(x)$, ta Ä‘áº¡o hÃ m $f'(x)$ sau Ä‘Ã³ cho $f'(x) = 0$ Ä‘á»ƒ tÃ¬m Ä‘Æ°á»£c giÃ¡ trá»‹ $x$ thoáº£ mÃ£n, gá»i lÃ  $\hat{x}$ Ä‘i.

Tiáº¿p theo, ta cÃ³ má»™t biáº¿n má»›i lÃ  $y$ vá»›i $x = g(y)$. Äá»•i biáº¿n hÃ m $f(x)$ sang $f(g(y))$ (lÃ  má»™t hÃ m cá»§a $y$), ta Ä‘áº·t $\tilde{f}(y) = f(g(y))$ (Ä‘á»ƒ biáº¿t Ä‘Ã¢y lÃ  má»™t hÃ m cá»§a $y$). Äá»ƒ tÃ¬m giÃ¡ trá»‹ lá»›n nháº¥t cá»§a $\tilde{f}(y)$, ta Ä‘áº¡o hÃ m vÃ  sau Ä‘Ã³ cho báº±ng $0$. Äáº§u tiÃªn Ä‘áº¡o hÃ m:

$$
\begin{aligned}
\frac{d\tilde{f}(y)}{dy} &= \frac{df(g(y))}{g(y)} \frac{dg(y)}{y} \\
\implies  \tilde{f}'(y) &= f'(g(y))g'(y)
\end{aligned}
$$

Sau Ä‘Ã³ cho báº±ng $0$ (gá»i giÃ¡ trá»‹ lÃ m Ä‘áº¡o hÃ m báº±ng $0$ lÃ  $\hat{y}$):

$$
\tilde{f}'(\hat{y}) = 0 \implies f'(g(\hat{y})) = 0 \hspace{3pt} \text{hoáº·c} \hspace{3pt} g'(\hat{y}) = 0 \hspace{3pt} \text{hoáº·c cáº£ 2 $=0$}
$$

{% include marginnote.html id="exercises_1" note="Tuy nhiÃªn ta cáº§n Ä‘á»ƒ Ã½ trÆ°á»ng há»£p chá»‰ $g'(\hat{y}) = 0$. Trong solution tÃ¡c giáº£ giáº£ sá»­ luÃ´n $g'(\hat{y}) = 0$ bá»Ÿi vÃ¬ ta chá»‰ quan tÃ¢m Ä‘áº¿n trÆ°á»ng há»£p $f'(g(\hat{y})) = 0$ thÃ´i, viá»‡c $g'(\hat{y}) = 0$ mÃ  $f'(g(\hat{y})) \neq 0$ cÃ³ thá»ƒ Ä‘Æ°á»£c giáº£i quyáº¿t báº±ng cÃ¡ch chá»n má»™t biáº¿n khÃ¡c, gá»i lÃ  $t$ Ä‘i, lÃºc nÃ y $x = \tilde{g}(t)$ vÃ  ta Ä‘Æ°á»£c $f'(\tilde{g}(\hat{t})) = 0$ vÃ  ta khÃ´ng cáº§n quan tÃ¢m $\tilde{g}'(\hat{t})$ báº±ng $0$ hay khÃ¡c $0$ ná»¯a. Do má»¥c Ä‘Ã­ch lÃ  tÃ¬m giÃ¡ trá»‹ lá»›n nháº¥t cá»§a $f(x)$ thÃ´ng qua má»™t biáº¿n má»›i nÃ o Ä‘Ã³, do Ä‘Ã³ ta cÃ³ thá»ƒ chá»n láº¡i biáº¿n má»›i sao cho thoáº£ mÃ£n cÃ¡c giáº£ sá»­ cá»§a ta lÃ  Ä‘Æ°á»£c. Váº­y á»Ÿ Ä‘Ã¢y, tÃ¡c giáº£ muá»‘n nÃ³i lÃ , vá»›i $x$ vÃ  $y$ (liÃªn quan vá»›i nhau thÃ´ng qua $x = g(y)$) khÃ´ng lÃ  biáº¿n ngáº«u nhiÃªn thÃ¬ ta cÃ³ thá»ƒ tÃ¬m giÃ¡ trá»‹ lá»›n nháº¥t cá»§a $f(x)$ thÃ´ng qua $y$. NhÆ°ng Ä‘á»‘i vá»›i hai biáº¿n ngáº«u nhiÃªn $X$ vÃ  $Y$ thÃ¬ viá»‡c nÃ y khÃ´ng xáº£y ra (khÃ´ng thá»ƒ tÃ¬m giÃ¡ trá»‹ lá»›n $f(X)$ thÃ´ng $Y$) do bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi jacobian factor." %}

XÃ©t trÆ°á»ng há»£p $f'(g(\hat{y})) = 0$, ta tháº¥y ráº±ng $f'(\hat{x}) = 0$, do Ä‘Ã³ $f'(g(\hat{y})) = f'(\hat{x}) \implies g(\hat{y}) = \hat{x}$. Váº­y cÃ³ nghÄ©a lÃ  ta cÃ³ thá»ƒ tÃ¬m giÃ¡ trá»‹ lá»›n nháº¥t cá»§a $f(x)$ thÃ´ng qua $y$ vá»›i $x = g(y)$. TÆ°Æ¡ng tá»± vá»›i trÆ°á»ng há»£p $f'(g(\hat{y})) = 0$ vÃ  $g'(\hat{y}) = 0$.

Giá» xÃ©t $X$ vÃ  $Y$ lÃ  hai biáº¿n ngáº«u nhiÃªn vá»›i $X = g(Y$) (lÆ°u Ã½ $g$ lÃ  hÃ m kháº£ nghá»‹ch). Äáº·t $p_x$ vÃ  $p_y$ láº§n lÆ°á»£t lÃ  hÃ m máº­t Ä‘á»™ xÃ¡c suáº¥t cá»§a $X$ vÃ  $Y$. Äá»ƒ tÃ¬m Ä‘Æ°á»£c máº­t Ä‘á»™ xÃ¡c suáº¥t cá»§a $Y$, ta dÃ¹ng cÃ´ng thá»©c 1.17 nhÆ° sau:

$$
p_{y}(y) = p_{x}(g(y)) \hspace{2pt} \left|g'(y)\right|
$$

Giáº£ sá»­ giÃ¡ trá»‹ $\hat{x}$ lÃ  giÃ¡ trá»‹ Ä‘á»ƒ lÃ m cho $p_x$ lá»›n nháº¥t, tá»©c lÃ  $p_{x}'(\hat{x}) = 0$. Äá»ƒ tÃ¬m giÃ¡ trá»‹ lá»›n nháº¥t cá»§a $p_y(y)$ ta Ä‘áº¡o hÃ m vÃ  sau Ä‘Ã³ cho giÃ¡ trá»‹ Ä‘áº¡o hÃ m báº±ng $0$. Giáº£ sá»­ $g'(y) \neq 0$ (khi Ä‘Ã³ ta má»›i cÃ³ thá»ƒ Ä‘áº¡o hÃ m $\lvert g'(y)\rvert$) vÃ  Ä‘áº·t $\lvert g'(y) \rvert= sg'(y)$ vá»›i $s \in \{-1, 1\}$.

Äáº§u tiÃªn ta láº¥y Ä‘áº¡o hÃ m:

$$
\begin{aligned}
p_{y}'(y) = \frac{dp_{y}(y)}{dy} &= \frac{dp_{x}(g(y))}{dy} sg'(y) + p_{x}(g(y)) \frac{dsg'(y)}{dy} \\
&= sp_{x}'(g(y))g'(y)\hspace{1pt}|g'(y)| + p_{x}(g(y))\hspace{1pt}sg''(y) \\
&= sp_{x}'(g(y))[g'(y)]^2 + sp_{x}(g(y))\hspace{1pt}g''(y) \\
\end{aligned}
$$

Giáº£ sá»­ giÃ¡ trá»‹ $\hat{y}$ lÃ  giÃ¡ trá»‹ Ä‘á»ƒ lÃ m cho $p_y$ lá»›n nháº¥t vÃ  **giáº£ sá»­** $\hat{x} = g(\hat{y})$, tá»©c lÃ  $p_x(\hat{x}) = p_x(g(\hat{y})) = 0$ (tÆ°Æ¡ng tá»± nhÆ° $x$ vÃ  $y$ khÃ´ng lÃ  biáº¿n ngáº«u nhiÃªn). Khi Ä‘Ã³:

$$
\begin{aligned}
p_{y}'(\hat{y}) &= sp_{x}'(g(\hat{y}))[g'(\hat{y})]^2 + sp_{x}(g(\hat{y}))\hspace{1pt}g''(\hat{y}) \\ 
&= sp_{x}(g(\hat{y}))g''(\hat{y}) \neq 0
\end{aligned}
$$

Váº­y rÃµ rÃ ng náº¿u $\hat{y}$ lÃ  giÃ¡ trá»‹ lÃ m cho $p_y$ lá»›n nháº¥t vÃ  $\hat{x} =g(\hat{y})$ thÃ¬ Ä‘iá»u nÃ y láº¡i sai, do Ä‘Ã³ $\hat{x} \neq g(\hat{y})$. Tá»©c lÃ  náº¿u $X$ vÃ  $Y$ lÃ  biáº¿n ngáº«u nhiÃªn thÃ¬ khÃ´ng cÃ³ quan há»‡ nÃ o giá»¯a $\hat{x}$ vÃ  $g(\hat{y})$, do Ä‘Ã³ ta khÃ´ng thá»ƒ tÃ¬m giÃ¡ trá»‹ $X$ lÃ m cho $p_x$ lá»›n nháº¥t báº±ng cÃ¡ch tÃ¬m giÃ¡ trá»‹ $Y$ lÃ m cho $p_y$ lá»›n nháº¥t.

Tuy nhiÃªn, náº¿u ta chá»n $g(Y) = X$ sao cho $g$ lÃ  má»™t hÃ m tuyáº¿n tÃ­nh thÃ¬ má»i chuyá»‡n sáº½ khÃ¡c. Giáº£ sá»­ $X = g(Y) = \alpha Y + \beta$. Khi Ä‘Ã³:

$$
p'_{y}(\hat{y}) = sp_{x}(g(\hat{y}))g''(\hat{y}) = 0
$$

Do náº¿u $g(y) = \alpha y + \beta$ thÃ¬ $g''(y) = 0$ vá»›i má»i $y$.

Váº­y $p_y'(\hat{y}) = 0 \implies p_x'(g(\hat{y})) = 0 \implies p_x'(\hat{x}) = p_{x}(g(\hat{y})) = 0 \implies  \hat{x} = g(\hat{y})$. Ta cÃ³ thá»ƒ tháº¥y báº±ng viá»‡c chá»n $g$ lÃ  má»™t hÃ m tuyáº¿n tÃ­nh thÃ¬ $\hat{x} = g(\hat{y})$, do Ä‘Ã³ viá»‡c chá»n hÃ m $g$ Ä‘á»ƒ biáº¿n Ä‘á»•i tá»« $X$ sang $Y$ lÃ  ráº¥t quan trá»ng.

**References**:
- [prml-web-sol.dvi (microsoft.com)](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/05/prml-web-sol-2009-09-08.pdf)
- [real analysis - Exercise 1.4 from PRML: Process of Using Transformations to Find Modes of PDFs - Mathematics Stack Exchange](https://math.stackexchange.com/questions/3494289/exercise-1-4-from-prml-process-of-using-transformations-to-find-modes-of-pdfs)
- [real analysis - Linear/non-linear change of variables: $\tilde{f} \ ' (\tilde{y}) = f'(g(\tilde{y})) g'(\tilde{y}) = 0$ and assuming $g'(\tilde{y}) \not= 0$ - Mathematics Stack Exchange](https://math.stackexchange.com/questions/3510938/linear-non-linear-change-of-variables-tildef-tildey-fg-tilde)